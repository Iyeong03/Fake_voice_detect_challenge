{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/oem/sw/data/sum_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m train_df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/home/oem/sw/data/sum_train.csv')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAWBXQE</td>\n",
       "      <td>./train/AAAWBXQE.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAWBXQE_PKNGFCHH_double</td>\n",
       "      <td>./fake_fake/AAAWBXQE_PKNGFCHH_double.wav</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AABHDRLX</td>\n",
       "      <td>./train/AABHDRLX.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AABHDRLX_MYTQQKLT_double</td>\n",
       "      <td>./fake_fake/AABHDRLX_MYTQQKLT_double.wav</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AABXXHMU</td>\n",
       "      <td>./train/AABXXHMU.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83014</th>\n",
       "      <td>ZZXEFKCS_YDSPLJMK_double</td>\n",
       "      <td>./fake_fake/ZZXEFKCS_YDSPLJMK_double.wav</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83020</th>\n",
       "      <td>ZZYYUTZI</td>\n",
       "      <td>./train/ZZYYUTZI.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83021</th>\n",
       "      <td>ZZYYUTZI_RXVBDTAP_double</td>\n",
       "      <td>./fake_fake/ZZYYUTZI_RXVBDTAP_double.wav</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83024</th>\n",
       "      <td>ZZZJMLBU</td>\n",
       "      <td>./train/ZZZJMLBU.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83027</th>\n",
       "      <td>ZZZSAANM</td>\n",
       "      <td>./train/ZZZSAANM.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41367 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id                                      path  \\\n",
       "3                      AAAWBXQE                      ./train/AAAWBXQE.ogg   \n",
       "4      AAAWBXQE_PKNGFCHH_double  ./fake_fake/AAAWBXQE_PKNGFCHH_double.wav   \n",
       "5                      AABHDRLX                      ./train/AABHDRLX.ogg   \n",
       "6      AABHDRLX_MYTQQKLT_double  ./fake_fake/AABHDRLX_MYTQQKLT_double.wav   \n",
       "7                      AABXXHMU                      ./train/AABXXHMU.ogg   \n",
       "...                         ...                                       ...   \n",
       "83014  ZZXEFKCS_YDSPLJMK_double  ./fake_fake/ZZXEFKCS_YDSPLJMK_double.wav   \n",
       "83020                  ZZYYUTZI                      ./train/ZZYYUTZI.ogg   \n",
       "83021  ZZYYUTZI_RXVBDTAP_double  ./fake_fake/ZZYYUTZI_RXVBDTAP_double.wav   \n",
       "83024                  ZZZJMLBU                      ./train/ZZZJMLBU.ogg   \n",
       "83027                  ZZZSAANM                      ./train/ZZZSAANM.ogg   \n",
       "\n",
       "      label  \n",
       "3      real  \n",
       "4      real  \n",
       "5      real  \n",
       "6      real  \n",
       "7      real  \n",
       "...     ...  \n",
       "83014  real  \n",
       "83020  real  \n",
       "83021  real  \n",
       "83024  real  \n",
       "83027  real  \n",
       "\n",
       "[41367 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_real = train_df[train_df['label'] == 'real']\n",
    "train_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real.to_csv('/home/oem/sw/data/train_real.csv', index=False, columns = ['id', 'path', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACWKPZ</td>\n",
       "      <td>./train/AAACWKPZ.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACWKPZ_YDNYIBEK_double</td>\n",
       "      <td>./fake_fake/AAACWKPZ_YDNYIBEK_double.wav</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAQOZYI</td>\n",
       "      <td>./train/AAAQOZYI.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AADPDAER</td>\n",
       "      <td>./train/AADPDAER.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AADPDAER_HNXLBANC_double</td>\n",
       "      <td>./fake_fake/AADPDAER_HNXLBANC_double.wav</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83025</th>\n",
       "      <td>ZZZMJSBX</td>\n",
       "      <td>./train/ZZZMJSBX.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83026</th>\n",
       "      <td>ZZZRTSKN</td>\n",
       "      <td>./train/ZZZRTSKN.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83028</th>\n",
       "      <td>ZZZSYEYS</td>\n",
       "      <td>./train/ZZZSYEYS.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83029</th>\n",
       "      <td>ZZZSYEYS_LFNVGMHK_double</td>\n",
       "      <td>./fake_fake/ZZZSYEYS_LFNVGMHK_double.wav</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83030</th>\n",
       "      <td>ZZZTCIWY</td>\n",
       "      <td>./train/ZZZTCIWY.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41664 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id                                      path  \\\n",
       "0                      AAACWKPZ                      ./train/AAACWKPZ.ogg   \n",
       "1      AAACWKPZ_YDNYIBEK_double  ./fake_fake/AAACWKPZ_YDNYIBEK_double.wav   \n",
       "2                      AAAQOZYI                      ./train/AAAQOZYI.ogg   \n",
       "22                     AADPDAER                      ./train/AADPDAER.ogg   \n",
       "23     AADPDAER_HNXLBANC_double  ./fake_fake/AADPDAER_HNXLBANC_double.wav   \n",
       "...                         ...                                       ...   \n",
       "83025                  ZZZMJSBX                      ./train/ZZZMJSBX.ogg   \n",
       "83026                  ZZZRTSKN                      ./train/ZZZRTSKN.ogg   \n",
       "83028                  ZZZSYEYS                      ./train/ZZZSYEYS.ogg   \n",
       "83029  ZZZSYEYS_LFNVGMHK_double  ./fake_fake/ZZZSYEYS_LFNVGMHK_double.wav   \n",
       "83030                  ZZZTCIWY                      ./train/ZZZTCIWY.ogg   \n",
       "\n",
       "      label  \n",
       "0      fake  \n",
       "1      fake  \n",
       "2      fake  \n",
       "22     fake  \n",
       "23     fake  \n",
       "...     ...  \n",
       "83025  fake  \n",
       "83026  fake  \n",
       "83028  fake  \n",
       "83029  fake  \n",
       "83030  fake  \n",
       "\n",
       "[41664 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fake = train_df[train_df['label'] == 'fake']\n",
    "train_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fake.to_csv('/home/oem/sw/data/train_fake.csv', index=False, columns = ['id', 'path', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, max_length=10000, is_test=False):\n",
    "        self.csv_file = csv_file\n",
    "        self.root_dir = root_dir\n",
    "        self.max_length = max_length\n",
    "        self.is_test = is_test\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.ids = []\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        data = pd.read_csv(self.csv_file)\n",
    "\n",
    "        for _, row in tqdm(data.iterrows(), total=len(data)):\n",
    "            file_path = os.path.join(self.root_dir, 'test_wav' if self.is_test else 'train_wav', f\"{row['id']}.wav\")\n",
    "            if os.path.exists(file_path):\n",
    "                waveform, sample_rate = torchaudio.load(file_path)\n",
    "                # print(sample_rate)\n",
    "                # print(waveform.shape)\n",
    "                # waveform = self.normalize_waveform(waveform)\n",
    "            else:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "                continue\n",
    "            \n",
    "            self.data.append(waveform)\n",
    "            if not self.is_test:\n",
    "                label = 1 if row['label'] == 'fake' else 0\n",
    "                self.labels.append(label)\n",
    "            self.ids.append(row['id'])\n",
    "        \n",
    "        print(f\"Loaded {len(self.data)} samples\")\n",
    "\n",
    "    # def normalize_waveform(self, waveform):\n",
    "    #     return (waveform - waveform.mean()) / waveform.std()\n",
    "    \n",
    "    def pad_waveform(self, waveform):\n",
    "        if waveform.size(1) < self.max_length:\n",
    "            padded_wav = torch.zeros((waveform.size(0), self.max_length))\n",
    "            padded_wav[:, :waveform.size(1)] = waveform\n",
    "        else:\n",
    "            padded_wav = waveform[:, :self.max_length]\n",
    "        return padded_wav\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        waveform = self.data[idx]\n",
    "        waveform = self.pad_waveform(waveform)\n",
    "\n",
    "        # (sequence_length) 형식으로 변환\n",
    "        waveform = waveform.squeeze(0)\n",
    "        sample = {'waveform': waveform, 'id': self.ids[idx]}\n",
    "        if not self.is_test:\n",
    "            sample['label'] = self.labels[idx]\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oem/anaconda3/envs/sw/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor\n",
    "\n",
    "# 모델 및 프로세서 로드\n",
    "model_name_1 = \"facebook/wav2vec2-base-960h\"\n",
    "model_name_2 = \"facebook/wav2vec2-large-960h\"\n",
    "model_1 = Wav2Vec2ForSequenceClassification.from_pretrained(model_name_1, num_labels=1)\n",
    "model_2 = Wav2Vec2ForSequenceClassification.from_pretrained(model_name_2, num_labels=1)\n",
    "# processor = Wav2Vec2Processor.from_pretrained(model_name_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:1\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Train data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "epochs = 10\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# 데이터셋 및 데이터로더 초기화\n",
    "csv_file = '/home/oem/sw/data/train_real.csv'\n",
    "root_dir = '/home/oem/sw/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41367/41367 [01:09<00:00, 592.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 41367 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(csv_file=csv_file, root_dir=root_dir)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def info_nce_loss(feats, temperature=0.07):\n",
    "    cos_sim = F.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "    self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "    cos_sim.masked_fill_(self_mask, -1e5)  # 대각선 부분을 큰 음수로 채움\n",
    "    pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "    cos_sim = cos_sim / temperature\n",
    "\n",
    "    nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "    nll = nll.mean()\n",
    "\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5171/5171 [07:30<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Model 1 Loss: 1.9850856695108776, Model 2 Loss: 1.9700105950809774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5171/5171 [07:36<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Model 1 Loss: 1.9537087647095568, Model 2 Loss: 1.9858818035064871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5171/5171 [07:31<00:00, 11.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Model 1 Loss: 1.9681353983300909, Model 2 Loss: 2.0411156687969814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 152/5171 [00:13<07:21, 11.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 역전파 및 옵티마이저 스텝\u001b[39;00m\n\u001b[1;32m     33\u001b[0m optimizer_1\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 34\u001b[0m \u001b[43mloss_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m optimizer_1\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     37\u001b[0m optimizer_2\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/sw/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sw/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sw/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 옵티마이저 및 손실 함수 정의\n",
    "optimizer_1 = AdamW(model_1.parameters(), lr=learning_rate)\n",
    "optimizer_2 = AdamW(model_2.parameters(), lr=learning_rate)\n",
    "\n",
    "model_1.to(device)\n",
    "model_2.to(device)\n",
    "\n",
    "# 모델 훈련\n",
    "model_1.train()\n",
    "model_2.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss_1 = 0.0\n",
    "    total_loss_2 = 0.0\n",
    "    for batch_idx, data in enumerate(tqdm(train_loader)):\n",
    "        waveforms = data['waveform'].to(device)\n",
    "        labels = data['label'].clone().detach().to(device)\n",
    "        #print(waveforms.shape)\n",
    "        \n",
    "        # 입력 데이터 전처리\n",
    "        #inputs = processor(waveforms, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "        \n",
    "        # print(waveforms.shape)\n",
    "\n",
    "        # 모델 1 출력 계산 및 손실 계산\n",
    "        outputs_1 = model_1(waveforms)\n",
    "        loss_1 = info_nce_loss(outputs_1.logits)\n",
    "        \n",
    "        # 모델 2 출력 계산 및 손실 계산\n",
    "        outputs_2 = model_2(waveforms)\n",
    "        loss_2 = info_nce_loss(outputs_2.logits)\n",
    "        \n",
    "        # 역전파 및 옵티마이저 스텝\n",
    "        optimizer_1.zero_grad()\n",
    "        loss_1.backward()\n",
    "        optimizer_1.step()\n",
    "        \n",
    "        optimizer_2.zero_grad()\n",
    "        loss_2.backward()\n",
    "        optimizer_2.step()\n",
    "        \n",
    "        total_loss_1 += loss_1.item()\n",
    "        total_loss_2 += loss_2.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Model 1 Loss: {total_loss_1/len(train_loader)}, Model 2 Loss: {total_loss_2/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /home/oem/sw/save_model/w2v_real_model3.pth\n",
      "Model saved to /home/oem/sw/save_model/w2v_real_model4.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_1.state_dict(), '/home/oem/sw/save_model/w2v_real_model3.pth')\n",
    "torch.save(model_2.state_dict(), '/home/oem/sw/save_model/w2v_real_model4.pth')\n",
    "\n",
    "print(f\"Model saved to /home/oem/sw/save_model/w2v_real_model3.pth\")\n",
    "print(f\"Model saved to /home/oem/sw/save_model/w2v_real_model4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/oem/sw/save_model/w2v_real_model1.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model_1 \u001b[38;5;241m=\u001b[39m Wav2Vec2ForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_1, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m model_2 \u001b[38;5;241m=\u001b[39m Wav2Vec2ForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_2, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m model_1\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/oem/sw/save_model/w2v_real_model1.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m model_2\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/oem/sw/save_model/w2v_real_model2.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      7\u001b[0m model_1\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/sw/lib/python3.11/site-packages/torch/serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/sw/lib/python3.11/site-packages/torch/serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/sw/lib/python3.11/site-packages/torch/serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/oem/sw/save_model/w2v_real_model1.pth'"
     ]
    }
   ],
   "source": [
    "model_1 = Wav2Vec2ForSequenceClassification.from_pretrained(model_name_1, num_labels=1)\n",
    "model_2 = Wav2Vec2ForSequenceClassification.from_pretrained(model_name_2, num_labels=1)\n",
    "\n",
    "model_1.load_state_dict(torch.load(\"/home/oem/sw/save_model/w2v_real_model1.pth\"))\n",
    "model_2.load_state_dict(torch.load(\"/home/oem/sw/save_model/w2v_real_model2.pth\"))\n",
    "\n",
    "model_1.to(device)\n",
    "model_2.to(device)\n",
    "\n",
    "model_1.eval()\n",
    "model_2.eval()\n",
    "\n",
    "print(f\"Model_1 loaded from /home/oem/sw/save_model/w2v_real_model1.pth\")\n",
    "print(f\"Model_2 loaded from /home/oem/sw/save_model/w2v_real_model2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [03:25<00:00, 243.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "csv_file = '/home/oem/sw/data/test.csv'\n",
    "\n",
    "test_dataset = CustomDataset(csv_file=csv_file, root_dir=root_dir, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [09:56<00:00, 20.94it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(tqdm(test_loader)):\n",
    "        waveforms = data['waveform'].to(device)\n",
    "        \n",
    "        outputs_1 = model_1(waveforms)\n",
    "        outputs_2 = model_2(waveforms)\n",
    "        \n",
    "        probs_1 = torch.sigmoid(outputs_1.logits).squeeze()\n",
    "        probs_2 = torch.sigmoid(outputs_2.logits).squeeze()\n",
    "        \n",
    "        final_probs = (probs_1 + probs_2) / 2\n",
    "        \n",
    "        for i in range(final_probs.shape[0]):\n",
    "            pred = {\n",
    "                'id': data['id'][i],\n",
    "                # 'fake': final_probs[i, 1].item(),\n",
    "                'real': final_probs[i].item()\n",
    "            }\n",
    "            predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>0.513379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>0.512487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>0.512406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>0.513182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>0.512507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>TEST_49995</td>\n",
       "      <td>0.511279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>TEST_49996</td>\n",
       "      <td>0.477292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>TEST_49997</td>\n",
       "      <td>0.513540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>TEST_49998</td>\n",
       "      <td>0.515091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>TEST_49999</td>\n",
       "      <td>0.511893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      real\n",
       "0      TEST_00000  0.513379\n",
       "1      TEST_00001  0.512487\n",
       "2      TEST_00002  0.512406\n",
       "3      TEST_00003  0.513182\n",
       "4      TEST_00004  0.512507\n",
       "...           ...       ...\n",
       "49995  TEST_49995  0.511279\n",
       "49996  TEST_49996  0.477292\n",
       "49997  TEST_49997  0.513540\n",
       "49998  TEST_49998  0.515091\n",
       "49999  TEST_49999  0.511893\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real_predictions = pd.DataFrame(predictions)\n",
    "df_real_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_predictions.to_csv('/home/oem/sw/submission/w2v_real.csv', index=False, columns = ['id', 'real'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake Train data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41664/41664 [00:56<00:00, 734.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 41664 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "csv_file = '/home/oem/sw/data/train_fake.csv'\n",
    "root_dir = '/home/oem/sw/data'\n",
    "\n",
    "fake_train_dataset = CustomDataset(csv_file=csv_file, root_dir=root_dir)\n",
    "fake_train_loader = DataLoader(fake_train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5208/5208 [20:20<00:00,  4.27it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     total_loss_1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_1\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     42\u001b[0m     total_loss_2 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_2\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Model 1 Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss_1\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_loader\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Model 2 Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss_2\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# 옵티마이저 및 손실 함수 정의\n",
    "optimizer_1 = AdamW(model_1.parameters(), lr=learning_rate)\n",
    "optimizer_2 = AdamW(model_2.parameters(), lr=learning_rate)\n",
    "\n",
    "model_1.to(device)\n",
    "model_2.to(device)\n",
    "\n",
    "# 모델 훈련\n",
    "model_1.train()\n",
    "model_2.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss_1 = 0.0\n",
    "    total_loss_2 = 0.0\n",
    "    for batch_idx, data in enumerate(tqdm(fake_train_loader)):\n",
    "        waveforms = data['waveform'].to(device)\n",
    "        labels = data['label'].clone().detach().to(device)\n",
    "        #print(waveforms.shape)\n",
    "        \n",
    "        # 입력 데이터 전처리\n",
    "        #inputs = processor(waveforms, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "        \n",
    "        # print(waveforms.shape)\n",
    "\n",
    "        # 모델 1 출력 계산 및 손실 계산\n",
    "        outputs_1 = model_1(waveforms)\n",
    "        loss_1 = info_nce_loss(outputs_1.logits)\n",
    "        \n",
    "        # 모델 2 출력 계산 및 손실 계산\n",
    "        outputs_2 = model_2(waveforms)\n",
    "        loss_2 = info_nce_loss(outputs_2.logits)\n",
    "        \n",
    "        # 역전파 및 옵티마이저 스텝\n",
    "        optimizer_1.zero_grad()\n",
    "        loss_1.backward()\n",
    "        optimizer_1.step()\n",
    "        \n",
    "        optimizer_2.zero_grad()\n",
    "        loss_2.backward()\n",
    "        optimizer_2.step()\n",
    "        \n",
    "        total_loss_1 += loss_1.item()\n",
    "        total_loss_2 += loss_2.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Model 1 Loss: {total_loss_1/len(fake_train_loader)}, Model 2 Loss: {total_loss_2/len(fake_train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Model 1 Loss: 1.9971224181296823, Model 2 Loss: 1.9524116807269611\n"
     ]
    }
   ],
   "source": [
    "print(f\"Epoch {epoch+1}/{epochs}, Model 1 Loss: {total_loss_1/len(fake_train_loader)}, Model 2 Loss: {total_loss_2/len(fake_train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /home/oem/sw/save_model/w2v_fake_model1.pth\n",
      "Model saved to /home/oem/sw/save_model/w2v_fake_model2.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_1.state_dict(), '/home/oem/sw/save_model/w2v_fake_model1.pth')\n",
    "torch.save(model_2.state_dict(), '/home/oem/sw/save_model/w2v_fake_model2.pth')\n",
    "\n",
    "print(f\"Model saved to /home/oem/sw/save_model/w2v_fake_model1.pth\")\n",
    "print(f\"Model saved to /home/oem/sw/save_model/w2v_fake_model2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1 loaded from /home/oem/sw/save_model/w2v_fake_model1.pth\n",
      "Model_2 loaded from /home/oem/sw/save_model/w2v_fake_model2.pth\n"
     ]
    }
   ],
   "source": [
    "model_1 = Wav2Vec2ForSequenceClassification.from_pretrained(model_name_1, num_labels=1)\n",
    "model_2 = Wav2Vec2ForSequenceClassification.from_pretrained(model_name_2, num_labels=1)\n",
    "\n",
    "model_1.load_state_dict(torch.load(\"/home/oem/sw/save_model/w2v_fake_model1.pth\"))\n",
    "model_2.load_state_dict(torch.load(\"/home/oem/sw/save_model/w2v_fake_model2.pth\"))\n",
    "\n",
    "model_1.to(device)\n",
    "model_2.to(device)\n",
    "\n",
    "model_1.eval()\n",
    "model_2.eval()\n",
    "\n",
    "print(f\"Model_1 loaded from /home/oem/sw/save_model/w2v_fake_model1.pth\")\n",
    "print(f\"Model_2 loaded from /home/oem/sw/save_model/w2v_fake_model2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [10:13<00:00, 20.38it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(tqdm(test_loader)):\n",
    "        waveforms = data['waveform'].to(device)\n",
    "        \n",
    "        outputs_1 = model_1(waveforms)\n",
    "        outputs_2 = model_2(waveforms)\n",
    "        \n",
    "        probs_1 = torch.sigmoid(outputs_1.logits).squeeze()\n",
    "        probs_2 = torch.sigmoid(outputs_2.logits).squeeze()\n",
    "        \n",
    "        final_probs = (probs_1 + probs_2) / 2\n",
    "        \n",
    "        for i in range(final_probs.shape[0]):\n",
    "            pred = {\n",
    "                'id': data['id'][i],\n",
    "                'fake': final_probs[i].item(),\n",
    "                # 'real': final_probs[i].item()\n",
    "            }\n",
    "            predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>0.404139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>0.407381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>0.406260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>0.405796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>0.405812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>TEST_49995</td>\n",
       "      <td>0.405429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>TEST_49996</td>\n",
       "      <td>0.408127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>TEST_49997</td>\n",
       "      <td>0.404169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>TEST_49998</td>\n",
       "      <td>0.405350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>TEST_49999</td>\n",
       "      <td>0.406678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      fake\n",
       "0      TEST_00000  0.404139\n",
       "1      TEST_00001  0.407381\n",
       "2      TEST_00002  0.406260\n",
       "3      TEST_00003  0.405796\n",
       "4      TEST_00004  0.405812\n",
       "...           ...       ...\n",
       "49995  TEST_49995  0.405429\n",
       "49996  TEST_49996  0.408127\n",
       "49997  TEST_49997  0.404169\n",
       "49998  TEST_49998  0.405350\n",
       "49999  TEST_49999  0.406678\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake_predictions = pd.DataFrame(predictions)\n",
    "df_fake_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake_predictions.to_csv('/home/oem/sw/submission/w2v_fake.csv', index=False, columns = ['id', 'fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>0.404139</td>\n",
       "      <td>0.513379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>0.407381</td>\n",
       "      <td>0.512487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>0.406260</td>\n",
       "      <td>0.512406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>0.405796</td>\n",
       "      <td>0.513182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>0.405812</td>\n",
       "      <td>0.512507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>TEST_49995</td>\n",
       "      <td>0.405429</td>\n",
       "      <td>0.511279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>TEST_49996</td>\n",
       "      <td>0.408127</td>\n",
       "      <td>0.477292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>TEST_49997</td>\n",
       "      <td>0.404169</td>\n",
       "      <td>0.513540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>TEST_49998</td>\n",
       "      <td>0.405350</td>\n",
       "      <td>0.515091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>TEST_49999</td>\n",
       "      <td>0.406678</td>\n",
       "      <td>0.511893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      fake      real\n",
       "0      TEST_00000  0.404139  0.513379\n",
       "1      TEST_00001  0.407381  0.512487\n",
       "2      TEST_00002  0.406260  0.512406\n",
       "3      TEST_00003  0.405796  0.513182\n",
       "4      TEST_00004  0.405812  0.512507\n",
       "...           ...       ...       ...\n",
       "49995  TEST_49995  0.405429  0.511279\n",
       "49996  TEST_49996  0.408127  0.477292\n",
       "49997  TEST_49997  0.404169  0.513540\n",
       "49998  TEST_49998  0.405350  0.515091\n",
       "49999  TEST_49999  0.406678  0.511893\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum = pd.merge(df_fake_predictions, df_real_predictions,on='id',how='outer')\n",
    "\n",
    "df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum.to_csv('/home/oem/sw/submission/w2v_independent.csv', index=False, columns = ['id', 'fake', 'real'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
